{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zaidalyafeai/AraMeter/blob/master/AraMeter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d0vjDuxuHl8",
    "outputId": "b21fbc5a-cba2-4c8e-81d4-5efe696202cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarabic\n",
      "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n",
      "Installing collected packages: pyarabic\n",
      "Successfully installed pyarabic-0.6.15\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarabic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Klf1-MC3DEhi"
   },
   "source": [
    "We use a product review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvOJw5Bg6c5J",
    "outputId": "92086685-1c5d-4f37-9eed-a0451659274f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  baits.zip\n",
      "  inflating: final_baits/labels.txt  \n",
      "  inflating: final_baits/test.txt    \n",
      "  inflating: final_baits/train.txt   \n"
     ]
    }
   ],
   "source": [
    "!unzip baits.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwlvjSR-DS15"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "23FSFg5t6fc1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from random import shuffle\n",
    "from pyarabic import araby\n",
    "from tensorflow.keras.layers import GRU, Embedding, Dense, Input, Dropout, Bidirectional, BatchNormalization, Flatten, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZZEFvXv2SqUg"
   },
   "outputs": [],
   "source": [
    "with open('final_baits/labels.txt', 'r') as f:\n",
    "  label2name = f.readlines()\n",
    "  label2name = [name.replace('\\n', '') for name in label2name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfbnvdT4Cmz0"
   },
   "source": [
    "## Read the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKhqB_MfCjEP"
   },
   "source": [
    "preprocess a review by removing special characters and long spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "T7MjMLLn6gtK"
   },
   "outputs": [],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "def extract_data(path, thresh = 70, on_shatrs = False):\n",
    "  global vocab\n",
    "\n",
    "  text = \"\"\n",
    "\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  t = open(path, 'r').read()\n",
    "  t = araby.strip_tashkeel(t)\n",
    "\n",
    "  # remove some exteranous chars\n",
    "  execluded = '!()*-ـ.:=o[]«»;؛,،~?؟\\u200f\\ufeffـ'\n",
    "  out = \"\"\n",
    "\n",
    "  for char in t:\n",
    "    if char not in execluded:\n",
    "      out += char\n",
    "\n",
    "  text += out\n",
    "  baits = out.split('\\n')\n",
    "  for line in baits:\n",
    "    if len(line) <= 1:\n",
    "      continue\n",
    "    label, bait = line.split(' ', 1)\n",
    "    label = int(label)\n",
    "\n",
    "    bait  = bait.strip()\n",
    "    if on_shatrs:\n",
    "      shatrs = bait.split('#')\n",
    "      for shatr in shatrs:\n",
    "        X.append(shatr.strip())\n",
    "        y.append(label)\n",
    "    else:\n",
    "      X.append(bait.strip())\n",
    "      y.append(label)\n",
    "\n",
    "  #create the vocab\n",
    "  vocab = sorted(set(' '.join(X)))\n",
    "\n",
    "  #shuffle the data\n",
    "  X, y = shuffle(X, y)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LWwTc-z2fv69"
   },
   "outputs": [],
   "source": [
    "X, y = extract_data(\"final_baits/train.txt\", on_shatrs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7oXawNaVyEL",
    "outputId": "abc9dd2b-6a87-4462-c311-5ef4d68a5891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "زكي النفس محمود السجايا # مصان العرض ممدوح الجناب   الوافر\n",
      "وأثمرت السمر هام الكماة # وعاجلنها بأوان الجناء   المتقارب\n",
      "قد أعلنت بالثناء تنشره # وابتهلت بالدعاء تخلصه   المنسرح\n",
      "جار ويرى ليس بجار # لأناة فيه ووقار   المتدارك\n",
      "قد حمى الغيران شمس هوى # منه عين الشمس في رمد   المديد\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  print(X[i], ' ', label2name[y[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syg_fvtnC1AK"
   },
   "source": [
    "## Create Sequences\n",
    "Create sequences by using the most repeated 500 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq0Ber9ICcWb"
   },
   "source": [
    "## Create Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ROef8aerf8ar"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size = 0.15, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "63NiojywQ18F"
   },
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i+1 for i, u in enumerate(vocab)}\n",
    "\n",
    "def to_sequences(X):\n",
    "  X = [[char2idx[char] for char in line] for line in X]\n",
    "  X = pad_sequences(X, padding='post', value=0, maxlen = 100)\n",
    "  return X\n",
    "\n",
    "X_train = to_sequences(X_train)\n",
    "X_valid = to_sequences(X_valid)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uHdRK4cCrGJ"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p3u3OxEcBfJ2"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((100,)))\n",
    "model.add(Embedding(len(char2idx)+1, 256))\n",
    "model.add(Bidirectional(GRU(units = 256, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(units = 256, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(units = 256)))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(label2name), activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7imJBjJHxK1-",
    "outputId": "d62df5d6-3f75-48af-e03f-c556012f12dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 256)          9984      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 100, 512)          789504    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 100, 512)          1182720   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 512)               1182720   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                1806      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3232398 (12.33 MB)\n",
      "Trainable params: 3232398 (12.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPyUsGe_u9tw",
    "outputId": "956ec7f5-7d19-4736-d657-1d3a3807f7e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.zeros((10, 100))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-7U36aDCtQu"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nEHRYgLhkozM"
   },
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001)]\n",
    "callbacks += [tf.keras.callbacks.ModelCheckpoint('full_verse.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52Ew-5ZyC3Nf",
    "outputId": "2d118082-58b1-4c82-f123-ce440c97506c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 2.1481 - accuracy: 0.2342\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45551, saving model to full_verse.h5\n",
      "313/313 [==============================] - 54s 111ms/step - loss: 2.1481 - accuracy: 0.2342 - val_loss: 1.5267 - val_accuracy: 0.4555 - lr: 0.0010\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - ETA: 0s - loss: 1.1348 - accuracy: 0.6177\n",
      "Epoch 2: val_accuracy improved from 0.45551 to 0.75173, saving model to full_verse.h5\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 1.1348 - accuracy: 0.6177 - val_loss: 0.7829 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.8299\n",
      "Epoch 3: val_accuracy improved from 0.75173 to 0.85090, saving model to full_verse.h5\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.5636 - accuracy: 0.8299 - val_loss: 0.4888 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8869\n",
      "Epoch 4: val_accuracy improved from 0.85090 to 0.88824, saving model to full_verse.h5\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.3885 - accuracy: 0.8869 - val_loss: 0.3784 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.9170\n",
      "Epoch 5: val_accuracy improved from 0.88824 to 0.89885, saving model to full_verse.h5\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.2959 - accuracy: 0.9170 - val_loss: 0.3562 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9312\n",
      "Epoch 6: val_accuracy improved from 0.89885 to 0.91187, saving model to full_verse.h5\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.2509 - accuracy: 0.9312 - val_loss: 0.3191 - val_accuracy: 0.9119 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9412\n",
      "Epoch 7: val_accuracy did not improve from 0.91187\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.2154 - accuracy: 0.9412 - val_loss: 0.3282 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9505\n",
      "Epoch 8: val_accuracy did not improve from 0.91187\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.1827 - accuracy: 0.9505 - val_loss: 0.3341 - val_accuracy: 0.9112 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9713\n",
      "Epoch 9: val_accuracy improved from 0.91187 to 0.93323, saving model to full_verse.h5\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.1114 - accuracy: 0.9713 - val_loss: 0.2728 - val_accuracy: 0.9332 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9796\n",
      "Epoch 10: val_accuracy improved from 0.93323 to 0.93479, saving model to full_verse.h5\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0850 - accuracy: 0.9796 - val_loss: 0.2772 - val_accuracy: 0.9348 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9837\n",
      "Epoch 11: val_accuracy did not improve from 0.93479\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.0729 - accuracy: 0.9837 - val_loss: 0.2838 - val_accuracy: 0.9322 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9857\n",
      "Epoch 12: val_accuracy did not improve from 0.93479\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0634 - accuracy: 0.9857 - val_loss: 0.2887 - val_accuracy: 0.9329 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9871\n",
      "Epoch 13: val_accuracy did not improve from 0.93479\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0554 - accuracy: 0.9871 - val_loss: 0.2948 - val_accuracy: 0.9337 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9889\n",
      "Epoch 14: val_accuracy did not improve from 0.93479\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0482 - accuracy: 0.9889 - val_loss: 0.3110 - val_accuracy: 0.9315 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9895\n",
      "Epoch 15: val_accuracy did not improve from 0.93479\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.0426 - accuracy: 0.9895 - val_loss: 0.3188 - val_accuracy: 0.9315 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f404d4bceb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data= (X_valid, y_valid), epochs = 15, batch_size= 128, shuffle = True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yVnnbxyUgDQ_"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('full_verse.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwZQrxhdDV4r"
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-Q-Texz3DQsH"
   },
   "outputs": [],
   "source": [
    "def classify(sentence):\n",
    "    sentence = araby.strip_tashkeel(sentence)\n",
    "    sequence = [char2idx[char] for char in sentence]\n",
    "    sequence = pad_sequences([sequence], maxlen = X_train.shape[1], padding='post', value=0)\n",
    "\n",
    "    pred = model.predict(sequence)[0]\n",
    "    predicted_label = label2name[np.argmax(pred, 0).astype('int')]\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDYjkqfDGS5m",
    "outputId": "bda47db6-7468-4d32-c69f-4324d25fc363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "الطويل\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "الخفيف\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "المتقارب\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "المنسرح\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "المتدارك\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "الكامل\n"
     ]
    }
   ],
   "source": [
    "classify(\"وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ # وَأَفرَعَ في لَومي مِراراً وَأَصعَدا\")\n",
    "classify(\"أَقصَدَتني سِهامُهُ إِذ رَأَتني # وَتَوَلَّت عَنهُ سُلَيمى نِبالي\")\n",
    "classify(\"تَحِنُّ حَنيناً إِلى مالِكٍ # فَحِنّي حَنينَكِ إِنّي مُعالي\")\n",
    "classify(\"لا تَغبِطِ المَرءَ أَن يُقالَ لَهُ # أَمسى فَلانٌ لِعُمرِهِ حَكَما\")\n",
    "classify(\"يا ليلُ الصبّ متى غدهُ # أقيامُ الساعة موعدهُ\")\n",
    "classify(\" لك يا منازل في القلوب منازل # أقفرت أنت وهن منك أواهل\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMgcfGkZRLF2",
    "outputId": "ff63bcf1-76d1-456c-fd3a-f6340ae3c152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "الرمل\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "الكامل\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "الكامل\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "الطويل\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "الهزج\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "المديد\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "الهزج\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "السريع\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "الخفيف\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "المتدارك\n"
     ]
    }
   ],
   "source": [
    "classify(\"ما تردون على هذا المحب # دائبا يشكو إليكم في الكتب\")\n",
    "classify(\"ولد الهدى فالكائنات ضياء # وفم الزمان تبسم وسناء\")\n",
    "classify(\" لك يا منازل في القلوب منازل # أقفرت أنت وهن منك أواهل\")\n",
    "classify(\"ومن لم يمت بالسيف مات بغيره # تعددت الأسباب والموت واحد\")\n",
    "classify(\"أنا النبي لا كذب # أنا ابن عبد المطلب\")\n",
    "classify(\"هذه دراهم اقفرت # أم ربور محتها الدهور\")\n",
    "classify(\"هزجنا في بواديكم # فأجزلتم عطايانا\")\n",
    "classify(\"بحر سريع ماله ساحل # مستفعلن مستفعلن فاعلن\")\n",
    "classify(\"مَا مَضَى فَاتَ وَالْمُؤَمَّلُ غَيْبٌ # وَلَكَ السَّاعَةُ الَّتِيْ أَنْتَ فِيْهَا\")\n",
    "classify(\"يا ليلُ الصبّ متى غدهُ # أقيامُ الساعة موعدهُ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0C1vwNk1du8",
    "outputId": "11b64ebd-57c7-47f7-9b8c-6d971728d4c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: full_verse.h5 (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!zip model.zip full_verse.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJ_Qh6OI1qP5",
    "outputId": "fdd1a4d0-f393-4183-add3-802ea22c2f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 75548\n",
      "-rw-r--r-- 1 root root  2422044 Nov  4 14:56 baits.zip\n",
      "drwxr-xr-x 2 root root     4096 Nov  4 15:03 final_baits\n",
      "-rw-r--r-- 1 root root 38894432 Nov  4 15:09 full_verse.h5\n",
      "-rw-r--r-- 1 root root 36032183 Nov  4 15:14 model.zip\n",
      "drwxr-xr-x 1 root root     4096 Nov  3 18:00 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
